---
id: ya137
name: Spider/scraper
file_version: 1.1.0
app_version: 1.0.6
---

# _Overview_

_The spidering package provides an API to build simple web page scrapers. Under the hood it uses Puppeteer to manage a headless browser. It provides several preconfigured levels of script and resource blocking, utilities to manage collections of downloaded pages, and extensive logging for monitoring browser events._

# _API Usage_

_A basic fetch function might look like the following:_

```typescript
const runScraper: Transform<URL, unknown> = compose(
  cleanArtifacts(), // delete any previously downloaded files for input URL
  fetchUrl(), // run the fetcher
  writeResponseBody() // write to disk
);
```

_A more complex example might allow JavaScript to run on certain domains, while other domains would only fetch the HTML document and block all other resources (the default behavior)_

```typescript
const tryAlternates = attemptEach( // try each function, stopping at first success
  compose(
    urlFilterAny([/aaai.org/, /umass.edu/]),
    fetchUrl({javaScriptEnabled=true, allowedResources=['document', 'script'] }),
  ),
  fetchUrl(),
);
```

_A working example is available in `ðŸ“„ packages/spider/src/app/cli.ts`,_

_Scraping primitives are defined in `ðŸ“„ packages/spider/src/app/scraping-primitives.ts`, and control-flow primitives are defined in `ðŸ“„ packages/spider/src/core/taskflow-defs.ts`._

<br/>

This file was generated by Swimm. [Click here to view it in the app](https://app.swimm.io/repos/Z2l0aHViJTNBJTNBb3Blbi1tZXRhLWV4dHJhY3Rpb24lM0ElM0FhZGFtY2hhbmRyYQ==/docs/ya137).
