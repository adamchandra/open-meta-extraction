{"kind":"fields","fields":{"abstract":{"exists":true,"count":2,"instances":[{"name":"abstract","evidence":["use-input:css-norm","lines:[/^ +div \\.hlFld-Abstract/ _ /^ +div/ _ /^ +div/ _ /^ +h2/]"],"value":"We study the optimization of a continuous function by its stochastic relaxation, i.e., the optimization of the expected value of the function itself with respect to a density in a statistical model. We focus on gradient descent techniques applied to models from the exponential family and in particular on the multivariate Gaussian distribution. From the theory of the exponential family, we reparametrize the Gaussian distribution using natural and expectation parameters, and we derive formulas for natural gradients in both parameterizations. We discuss some advantages of the natural parameterization for the identification of sub-models in the Gaussian distribution based on conditional independence assumptions among variables. Gaussian distributions are widely used in stochastic optimization and in particular in model-based Evolutionary Computation, as in Estimation of Distribution Algorithms and Evolutionary Strategies. By studying natural gradient flows over Gaussian distributions our analysis and results directly apply to the study of CMA-ES and NES algorithms."},{"name":"abstract","evidence":["use-input:css-norm","lines:[/^ +div \\.abstractSection/ _ /^ +p/]"],"value":"We study the optimization of a continuous function by its  statistical model. "}]}}}
